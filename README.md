# Описание статьи DreamBooth
В данном репозитории приведено краткое описание статьи [DreamBooth: Fine Tuning Text-to-Image Diffusion Models
for Subject-Driven Generation](https://www.google.com). Описание составлено в виде ответов на вопросы о статье.
## Что описывается в статье?
В статье описывается способ дообучения диффузионных 
text-to-image моделей на маленьком датасете 
(3-5 изображений какого-то конкретного объекта) с целью
генерации изображений, на которых с нужным промптом будет
изображён объект, очень похожий на тот объект, который
изображён на фотографиях в датасете для дообучения,
но в новом контексте (контекст зависит от промпта).
## Почему над этим работают?
Над этим работают для того,
чтобы иметь возможность решать актуальные
задачи с помощью машинного обучения, которые
раньше нельзя было автоматизировать с помощью
программирования. К таким задачам относится широкий
спектр семантических модификаций конкретного объекта
с помощью текста, включая реконтекстуализацию,
модификацию свойств объекта (цвет, форма и т.д.), 
создание изображения объекта в другом художественном 
стиле и изменение точки обзора на объект. Такие задачи
являются очень релевантными, так как возникают повсеместно
в жизни. У существующих моделей глубокого обучения 
есть возможность по текстовому запросу генерировать 
изображение объекта в новых условиях, но проблема 
состоит в том, что чтобы нейронная сеть сгенерировала 
изображение какого-то конкретного объекта в новых 
условиях, то надо этот объект очень глубоко описать 
в текстовом запросе, что не всегда легко, и даже с 
полным текстовым описанием объекта есть вероятность, 
что некоторые его свойства не сохранятся в сгенерированном
изображении. Из-за этого, с помощью обычных text-to-image
нейронных сетей нельзя решить задачи, описанные выше. 
Следовательно, возникает потребность в методе, который бы
решил такие задачи с хорошей точностью, так как задачи, 
описанные выше, очень актуальны. Поэтому люди и работают
над этой проблемой и разрабатывают методы, которые её 
эффективно решают с большей точностью и с меньшими
затратами по времени и по памяти.
## Как формулируется задача?
Формулировка задачи -  имея датасет из нескольких
изображений одного объекта (5 изображений будет достаточно)
и предварительно обученную диффузионную модель вида
text-to-image, дообучить эту модель на изображениях
объекта, чтобы она могла по текстовым запросам генерировать
новые изображения, которые являлись бы  различными
семантическими модификациями объекта из датасета,
описанными в прошлом пункте, сохраняя отличительные
свойства этого объекта.
## В чем ее основная идея?
Её основная идея состоит в том, чтобы внедрить пару
вида (уникальный идентификатор, объект) 
(объект - то, что изображено на датасете для дообучения
модели, уникальный идентификатор - строка определённого
вида),  в “словарь” диффузионной text-to-image модели,
чтобы модель могла по этому уникальному идентификатору 
в текстовом запросе генерировать изображения с привязанным
к этому идентификатору объектом в различных контекстах,
которые зависят от текстового запроса.
## В чем ее новаторство?
Её новаторство состоит в том, что авторы статьи первыми
предложили методику решения проблемы персонализированной
генерации изображений, которая позволяет, имея небольшое
количество изображений объекта в обыденных условиях, 
сгенерировать новые изображения с этим же объектом, либо
с его видоизменённой версией в разных контекстах, сохраняя
отличительные черты объекта. Кроме этого, они предложили 
новую функцию потерь, которая позволяет предварительно 
обученной на большом датасете диффузионной модели вида 
text-to-image не переобучаться в ходе дообучения на новом
датасете и генерировать разнообразные изображения с 
участием конкретного объекта из этого датасета. 
Это достигается с помощью использования в функции 
потерь не только специальных изображений из тренировочного
датасета, но и изображений, сгенерированных самой моделью.
Следовательно, модель обучается как на изображениях из 
тренировочного датасета, так и на изображениях, 
сгенерированных самой моделью.Такая функция потерь 
решает проблему меньшего разнообразия сгенерированных
изображений и проблему, известную как language drift,
которая возникает, когда модель, обученная на большом
массиве текста и впоследствии дообученная для определённого
узкоспециализированного задания, постепенно теряет 
синтаксическое и семантическое знание языка.
## Какие получились результаты?
Для оценки эффективности модели
использовались несколько метрик. Метрики CLIP-I и DINO 
использовались для оценки того, насколько
точно сохранился вид объекта на сгенерированных фотографиях.
Метрика CLIP-I это среднее попарное косинусное сходство между
CLIP кодированными сгенерированными моделью
изображениями и реальными изображениями.
Метрика CLIP-T, предназначенная для измерения того, насколько хорошо
сгенерированное изображение следует текстовому запросу,
это среднее попарное косинусное сходство между
текстовым запросом к модели и CLIP кодированным сгенерированным
моделью изображением.

На датасете, состоящем из 3000 изображений, 
который содержал изображения 30-ти различных объектов, метод DreamBooth
показал по этим метрикам впечатляющую эффективность. Его оценка сходства
объекта на сгенерированной фотографии с объектом, на котором дообучалась модель,
равна 68%, что примерно в 3 раза выше, чем у подобного метода
под названием Textual Inversion. А оценка того, насколько хорошо сгенерированная фотография
следует текстовому запросу, равна 81%, что примерно в 7 раз выше, чем у 
Textual Inversion.